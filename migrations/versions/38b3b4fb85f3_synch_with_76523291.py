"""Synch with 76523291

Revision ID: 38b3b4fb85f3
Revises:
Create Date: 2024-11-12 12:03:27.384483

"""

import sqlalchemy as sa
from alembic import op

# revision identifiers, used by Alembic.
revision = "38b3b4fb85f3"
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("users", schema=None) as batch_op:
        # Adding the 'full_name' column and 'preferences_email_list' column
        batch_op.add_column(sa.Column("full_name", sa.String(length=64), nullable=True))
        batch_op.add_column(
            sa.Column("preferences_email_list", sa.Boolean(), nullable=True)
        )

        # Create a unique constraint on 'full_name' with a specified name
        batch_op.create_unique_constraint(
            "uq_full_name", ["full_name"]
        )  # Specify the constraint name

    # Step 1: Add `supervisor_id` to the existing table
    op.add_column(
        "upload_sessions", sa.Column("supervisor_id", sa.Integer, nullable=True)
    )

    # Step 2: Rename `upload_sessions` to a temporary name
    op.execute("ALTER TABLE upload_sessions RENAME TO upload_sessions_old;")

    # Step 3: Recreate the `upload_sessions` table with named foreign key constraints
    op.create_table(
        "upload_sessions",
        sa.Column("id", sa.Integer, primary_key=True),
        sa.Column("session_title", sa.String(2048)),
        sa.Column("session_sushi_id", sa.String(64)),
        sa.Column("users_id", sa.Integer, nullable=False),
        sa.Column("supervisor_id", sa.Integer, nullable=True),
        sa.Column("is_bulk", sa.Boolean, nullable=False),
        sa.Column("remote_folder", sa.String(64), nullable=False),
        sa.Column("remote_password", sa.String(64), nullable=False),
        sa.Column("gather_job_id", sa.Integer, default=-1),
        sa.Column("gather_job_finished", sa.Boolean, default=False),
        sa.Column("upload_job_id", sa.Integer, default=-1),
        sa.Column("upload_job_finished", sa.Boolean, default=False),
        sa.Column("metadata_permission_user", sa.Integer, nullable=False),
        sa.Column("metadata_study_length", sa.Integer, default=8),
        sa.Column("metadata_contributors_number", sa.Integer, default=4),
        sa.Column("metadata_supplementary_number", sa.Integer, default=1),
        sa.Column("metadata_samples_displacement", sa.Integer, default=0),
        sa.Column("metadata_samples_length", sa.Integer, default=0),
        sa.Column("metadata_samples_width", sa.Integer, default=18),
        sa.Column("metadata_protocol_displacement", sa.Integer, default=0),
        sa.Column("metadata_protocol_length", sa.Integer, default=14),
        sa.Column("metadata_datasteps_number", sa.Integer, default=5),
        sa.Column("metadata_processedfiles_number", sa.Integer, default=2),
        sa.Column("metadata_pairedend_displacement", sa.Integer, default=0),
        # Named foreign key constraints
        sa.ForeignKeyConstraint(
            ["users_id"], ["users.id"], name="fk_upload_sessions_users_id"
        ),
        sa.ForeignKeyConstraint(
            ["supervisor_id"], ["users.id"], name="fk_upload_sessions_supervisor_id"
        ),
    )

    # Step 4: Copy data from the old table to the new table
    op.execute(
        """
        INSERT INTO upload_sessions (
            id, session_title, session_sushi_id, users_id,
            is_bulk, remote_folder, remote_password, gather_job_id,
            gather_job_finished, upload_job_id, upload_job_finished,
            metadata_permission_user, metadata_study_length,
            metadata_contributors_number, metadata_supplementary_number,
            metadata_samples_displacement, metadata_samples_length,
            metadata_samples_width, metadata_protocol_displacement,
            metadata_protocol_length, metadata_datasteps_number,
            metadata_processedfiles_number, metadata_pairedend_displacement
        )
        SELECT
            id, session_title, session_sushi_id, users_id,
            is_bulk, remote_folder, remote_password, gather_job_id,
            gather_job_finished, upload_job_id, upload_job_finished,
            metadata_permission_user, metadata_study_length,
            metadata_contributors_number, metadata_supplementary_number,
            metadata_samples_displacement, metadata_samples_length,
            metadata_samples_width, metadata_protocol_displacement,
            metadata_protocol_length, metadata_datasteps_number,
            metadata_processedfiles_number, metadata_pairedend_displacement
        FROM upload_sessions_old;
    """
    )

    # Step 5: Drop the old table
    op.execute("DROP TABLE upload_sessions_old;")


def downgrade():
    pass
